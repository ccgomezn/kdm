{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1\tMuscle loss\n",
    "- 2\t2-Oxoglutarate\n",
    "- 3\t3-Aminoisobutyrate\n",
    "- 4\tAdipate\n",
    "- 5\tBetaine\n",
    "- 6\tCreatinine\n",
    "- 7\tHypoxanthine\n",
    "- 8\tN,N-Dimethylglycine\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- 1\t3\n",
    "- 1\t4\n",
    "- 1\t5\n",
    "- 1\t7\n",
    "- 2\t7\n",
    "- 6\t7\n",
    "- 8\t5\n",
    "\n",
    "\n",
    "Directed GRAPH of the example - Comparison Accuracy 0.7532"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdm.models import KDMSequentialJointClassModel\n",
    "import kdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import metrics\n",
    "from keras import losses\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "import keras\n",
    "from pandas import read_csv, DataFrame\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv('cachexia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Muscle loss</th>\n",
       "      <th>1,6-Anhydro-beta-D-glucose</th>\n",
       "      <th>1-Methylnicotinamide</th>\n",
       "      <th>2-Aminobutyrate</th>\n",
       "      <th>2-Hydroxyisobutyrate</th>\n",
       "      <th>2-Oxoglutarate</th>\n",
       "      <th>3-Aminoisobutyrate</th>\n",
       "      <th>3-Hydroxybutyrate</th>\n",
       "      <th>3-Hydroxyisovalerate</th>\n",
       "      <th>...</th>\n",
       "      <th>Tryptophan</th>\n",
       "      <th>Tyrosine</th>\n",
       "      <th>Uracil</th>\n",
       "      <th>Valine</th>\n",
       "      <th>Xylose</th>\n",
       "      <th>cis-Aconitate</th>\n",
       "      <th>myo-Inositol</th>\n",
       "      <th>trans-Aconitate</th>\n",
       "      <th>pi-Methylhistidine</th>\n",
       "      <th>tau-Methylhistidine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PIF_178</td>\n",
       "      <td>cachexic</td>\n",
       "      <td>40.85</td>\n",
       "      <td>65.37</td>\n",
       "      <td>18.73</td>\n",
       "      <td>26.05</td>\n",
       "      <td>71.52</td>\n",
       "      <td>1480.30</td>\n",
       "      <td>56.83</td>\n",
       "      <td>10.07</td>\n",
       "      <td>...</td>\n",
       "      <td>259.82</td>\n",
       "      <td>290.03</td>\n",
       "      <td>111.05</td>\n",
       "      <td>86.49</td>\n",
       "      <td>72.24</td>\n",
       "      <td>237.46</td>\n",
       "      <td>135.64</td>\n",
       "      <td>51.94</td>\n",
       "      <td>157.59</td>\n",
       "      <td>160.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PIF_087</td>\n",
       "      <td>cachexic</td>\n",
       "      <td>62.18</td>\n",
       "      <td>340.36</td>\n",
       "      <td>24.29</td>\n",
       "      <td>41.68</td>\n",
       "      <td>67.36</td>\n",
       "      <td>116.75</td>\n",
       "      <td>43.82</td>\n",
       "      <td>79.84</td>\n",
       "      <td>...</td>\n",
       "      <td>83.10</td>\n",
       "      <td>167.34</td>\n",
       "      <td>46.99</td>\n",
       "      <td>109.95</td>\n",
       "      <td>192.48</td>\n",
       "      <td>333.62</td>\n",
       "      <td>376.15</td>\n",
       "      <td>217.02</td>\n",
       "      <td>307.97</td>\n",
       "      <td>130.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIF_090</td>\n",
       "      <td>cachexic</td>\n",
       "      <td>270.43</td>\n",
       "      <td>64.72</td>\n",
       "      <td>12.18</td>\n",
       "      <td>65.37</td>\n",
       "      <td>23.81</td>\n",
       "      <td>14.30</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.34</td>\n",
       "      <td>...</td>\n",
       "      <td>82.27</td>\n",
       "      <td>60.34</td>\n",
       "      <td>31.50</td>\n",
       "      <td>59.15</td>\n",
       "      <td>2164.62</td>\n",
       "      <td>330.30</td>\n",
       "      <td>86.49</td>\n",
       "      <td>58.56</td>\n",
       "      <td>145.47</td>\n",
       "      <td>83.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NETL_005_V1</td>\n",
       "      <td>cachexic</td>\n",
       "      <td>154.47</td>\n",
       "      <td>52.98</td>\n",
       "      <td>172.43</td>\n",
       "      <td>74.44</td>\n",
       "      <td>1199.91</td>\n",
       "      <td>555.57</td>\n",
       "      <td>175.91</td>\n",
       "      <td>25.03</td>\n",
       "      <td>...</td>\n",
       "      <td>235.10</td>\n",
       "      <td>323.76</td>\n",
       "      <td>30.57</td>\n",
       "      <td>102.51</td>\n",
       "      <td>125.21</td>\n",
       "      <td>1863.11</td>\n",
       "      <td>247.15</td>\n",
       "      <td>75.94</td>\n",
       "      <td>249.64</td>\n",
       "      <td>254.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIF_115</td>\n",
       "      <td>cachexic</td>\n",
       "      <td>22.20</td>\n",
       "      <td>73.70</td>\n",
       "      <td>15.64</td>\n",
       "      <td>83.93</td>\n",
       "      <td>33.12</td>\n",
       "      <td>29.67</td>\n",
       "      <td>76.71</td>\n",
       "      <td>69.41</td>\n",
       "      <td>...</td>\n",
       "      <td>103.54</td>\n",
       "      <td>142.59</td>\n",
       "      <td>44.26</td>\n",
       "      <td>160.77</td>\n",
       "      <td>186.79</td>\n",
       "      <td>101.49</td>\n",
       "      <td>749.95</td>\n",
       "      <td>98.49</td>\n",
       "      <td>84.77</td>\n",
       "      <td>79.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Patient ID Muscle loss  1,6-Anhydro-beta-D-glucose  1-Methylnicotinamide  \\\n",
       "0      PIF_178    cachexic                       40.85                 65.37   \n",
       "1      PIF_087    cachexic                       62.18                340.36   \n",
       "2      PIF_090    cachexic                      270.43                 64.72   \n",
       "3  NETL_005_V1    cachexic                      154.47                 52.98   \n",
       "4      PIF_115    cachexic                       22.20                 73.70   \n",
       "\n",
       "   2-Aminobutyrate  2-Hydroxyisobutyrate  2-Oxoglutarate  3-Aminoisobutyrate  \\\n",
       "0            18.73                 26.05           71.52             1480.30   \n",
       "1            24.29                 41.68           67.36              116.75   \n",
       "2            12.18                 65.37           23.81               14.30   \n",
       "3           172.43                 74.44         1199.91              555.57   \n",
       "4            15.64                 83.93           33.12               29.67   \n",
       "\n",
       "   3-Hydroxybutyrate  3-Hydroxyisovalerate  ...  Tryptophan  Tyrosine  Uracil  \\\n",
       "0              56.83                 10.07  ...      259.82    290.03  111.05   \n",
       "1              43.82                 79.84  ...       83.10    167.34   46.99   \n",
       "2               5.64                 23.34  ...       82.27     60.34   31.50   \n",
       "3             175.91                 25.03  ...      235.10    323.76   30.57   \n",
       "4              76.71                 69.41  ...      103.54    142.59   44.26   \n",
       "\n",
       "   Valine   Xylose  cis-Aconitate  myo-Inositol  trans-Aconitate  \\\n",
       "0   86.49    72.24         237.46        135.64            51.94   \n",
       "1  109.95   192.48         333.62        376.15           217.02   \n",
       "2   59.15  2164.62         330.30         86.49            58.56   \n",
       "3  102.51   125.21        1863.11        247.15            75.94   \n",
       "4  160.77   186.79         101.49        749.95            98.49   \n",
       "\n",
       "   pi-Methylhistidine  tau-Methylhistidine  \n",
       "0              157.59               160.77  \n",
       "1              307.97               130.32  \n",
       "2              145.47                83.93  \n",
       "3              249.64               254.68  \n",
       "4               84.77                79.84  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finish just Muscle loss, 3-Aminoisobutyrate, Adipate, Betaine and Hypoxanthine\n",
    "\n",
    "filtered_df = df[['Muscle loss', '3-Aminoisobutyrate', 'Adipate', 'Betaine', 'Hypoxanthine']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Muscle loss</th>\n",
       "      <th>3-Aminoisobutyrate</th>\n",
       "      <th>Adipate</th>\n",
       "      <th>Betaine</th>\n",
       "      <th>Hypoxanthine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cachexic</td>\n",
       "      <td>1480.30</td>\n",
       "      <td>38.09</td>\n",
       "      <td>109.95</td>\n",
       "      <td>97.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cachexic</td>\n",
       "      <td>116.75</td>\n",
       "      <td>327.01</td>\n",
       "      <td>244.69</td>\n",
       "      <td>82.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cachexic</td>\n",
       "      <td>14.30</td>\n",
       "      <td>131.63</td>\n",
       "      <td>116.75</td>\n",
       "      <td>114.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cachexic</td>\n",
       "      <td>555.57</td>\n",
       "      <td>144.03</td>\n",
       "      <td>278.66</td>\n",
       "      <td>223.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cachexic</td>\n",
       "      <td>29.67</td>\n",
       "      <td>15.03</td>\n",
       "      <td>391.51</td>\n",
       "      <td>66.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Muscle loss  3-Aminoisobutyrate  Adipate  Betaine  Hypoxanthine\n",
       "0    cachexic             1480.30    38.09   109.95         97.51\n",
       "1    cachexic              116.75   327.01   244.69         82.27\n",
       "2    cachexic               14.30   131.63   116.75        114.43\n",
       "3    cachexic              555.57   144.03   278.66        223.63\n",
       "4    cachexic               29.67    15.03   391.51         66.69"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2s/yq898nms72b5qxqbwz_hx8j80000gn/T/ipykernel_24297/903024324.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Muscle loss'] = filtered_df['Muscle loss'].apply(lambda x: 1 if x == 'cachexic' else 0)\n"
     ]
    }
   ],
   "source": [
    "# transform musche loss in 0-1\n",
    "filtered_df['Muscle loss'] = filtered_df['Muscle loss'].apply(lambda x: 1 if x == 'cachexic' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Muscle loss</th>\n",
       "      <th>3-Aminoisobutyrate</th>\n",
       "      <th>Adipate</th>\n",
       "      <th>Betaine</th>\n",
       "      <th>Hypoxanthine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1480.30</td>\n",
       "      <td>38.09</td>\n",
       "      <td>109.95</td>\n",
       "      <td>97.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>116.75</td>\n",
       "      <td>327.01</td>\n",
       "      <td>244.69</td>\n",
       "      <td>82.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14.30</td>\n",
       "      <td>131.63</td>\n",
       "      <td>116.75</td>\n",
       "      <td>114.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>555.57</td>\n",
       "      <td>144.03</td>\n",
       "      <td>278.66</td>\n",
       "      <td>223.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>29.67</td>\n",
       "      <td>15.03</td>\n",
       "      <td>391.51</td>\n",
       "      <td>66.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Muscle loss  3-Aminoisobutyrate  Adipate  Betaine  Hypoxanthine\n",
       "0            1             1480.30    38.09   109.95         97.51\n",
       "1            1              116.75   327.01   244.69         82.27\n",
       "2            1               14.30   131.63   116.75        114.43\n",
       "3            1              555.57   144.03   278.66        223.63\n",
       "4            1               29.67    15.03   391.51         66.69"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoded_size = 4\n",
    "dim_y = 2\n",
    "encoder = keras.layers.Identity()\n",
    "n_comp = 77\n",
    "sequences = [\n",
    "    {\n",
    "        'type': 'merge'\n",
    "    },\n",
    "    ]\n",
    "kdm_model = KDMSequentialJointClassModel(encoded_size=encoded_size,\n",
    "                                         dim_y=dim_y,\n",
    "                                         encoder=encoder,\n",
    "                                         n_comp=n_comp,\n",
    "                                         sequences=sequences,\n",
    "                                         sigma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdm_model.compile(optimizer=optimizers.Adam(learning_rate=5e-5),\n",
    "                  loss=losses.sparse_categorical_crossentropy,\n",
    "                  metrics=[metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for row in filtered_df.iterrows():\n",
    "    y = int(row[1]['Muscle loss'])\n",
    "    x = row[1][1:].values\n",
    "    data.append((x, y))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([1480.3 ,   38.09,  109.95,   97.51]), 1), (array([116.75, 327.01, 244.69,  82.27]), 1), (array([ 14.3 , 131.63, 116.75, 114.43]), 1), (array([555.57, 144.03, 278.66, 223.63]), 1), (array([ 29.67,  15.03, 391.51,  66.69]), 1), (array([17.46, 25.28, 66.69, 62.8 ]), 1), (array([ 56.26,   8.41, 149.9 ,  25.79]), 1), (array([ 8.67,  3.53, 15.33, 20.7 ]), 1), (array([17.99,  8.25, 31.19, 80.64]), 1), (array([ 57.97,  14.59, 149.9 ,  43.82]), 1), (array([ 93.69,  18.54, 219.2 ,  40.85]), 1), (array([105.64, 259.82, 137.  ,  33.78]), 1), (array([  8.08,  11.02, 167.34, 162.39]), 1), (array([43.38,  9.03, 56.83, 36.6 ]), 1), (array([ 2.97,  3.16, 41.68,  4.22]), 1), (array([6.36, 4.81, 4.06, 5.05]), 1), (array([ 31.82,  22.87, 157.59,  29.37]), 1), (array([16.12, 15.8 , 78.26, 92.76]), 1), (array([79.04, 12.43, 60.34, 42.52]), 1), (array([18.73, 20.49, 68.72, 23.81]), 1), (array([ 50.4 ,  18.54, 131.63,  45.6 ]), 1), (array([104.58,  28.79, 170.72, 165.67]), 1), (array([63.43, 23.1 , 66.02, 44.26]), 1), (array([ 2.97,  3.6 , 50.91,  6.49]), 1), (array([54.05,  6.11, 94.63, 14.3 ]), 1), (array([72.97, 32.14, 88.23, 24.05]), 1), (array([ 64.07,  68.72, 156.02, 265.07]), 1), (array([126.47,  14.15, 107.77,  24.05]), 1), (array([ 8.41,  5.81,  4.53, 29.37]), 1), (array([ 15.49,  21.33, 114.43,  97.51]), 1), (array([ 3.39,  8.94, 56.26, 13.2 ]), 1), (array([29.67,  8.5 , 64.72, 55.15]), 1), (array([ 22.42,  11.36, 127.74,  33.12]), 1), (array([ 11.7 ,  11.02, 208.51,  40.04]), 1), (array([21.76, 39.65, 22.87, 29.08]), 1), (array([13.07,  6.49, 45.15, 32.14]), 1), (array([ 53.52,  10.18, 347.23, 101.49]), 1), (array([561.16,  30.57, 116.75,  82.27]), 1), (array([  8.41,  13.2 , 126.47,  59.74]), 1), (array([ 8.41,  6.42, 75.94, 14.88]), 1), (array([184.93,  16.78, 146.94,  83.93]), 1), (array([354.25,  16.44,  39.25,  67.36]), 1), (array([26.84, 13.87, 34.12, 31.19]), 1), (array([ 14.15,  27.66, 130.32, 135.64]), 1), (array([ 19.49,  37.34, 120.3 , 194.42]), 1), (array([ 53.52,  57.97,  54.05, 165.67]), 1), (array([ 2.61,  3.94, 28.79,  7.77]), 1), (array([26.84,  3.35, 59.15,  3.78]), 0), (array([ 66.69,  19.11, 109.95,  57.97]), 0), (array([11.25,  3.9 ,  5.37, 12.18]), 0), (array([ 3.13,  6.42, 11.25,  5.16]), 0), (array([ 5.99,  4.81,  8.58, 12.68]), 0), (array([ 53.52,   6.17, 311.06, 131.63]), 0), (array([ 22.65,  18.54,  55.15, 162.39]), 0), (array([24.29,  3.46,  7.92,  7.77]), 0), (array([22.87,  3.46, 11.25,  6.11]), 0), (array([ 9.87,  5.37, 70.11, 24.53]), 0), (array([ 44.7 ,  14.15, 247.15, 146.94]), 0), (array([206.44,   6.23,  48.42,  90.92]), 0), (array([14.88, 16.12, 13.33, 44.7 ]), 0), (array([31.82,  8.  , 42.52, 59.74]), 0), (array([ 5.99,  1.99,  2.29, 15.18]), 0), (array([27.11,  8.58, 14.73, 75.19]), 0), (array([ 9.3 ,  2.53, 37.71, 39.25]), 0), (array([13.2 ,  1.55, 43.82,  9.3 ]), 0), (array([ 7.03, 11.47, 21.76, 31.82]), 0), (array([ 10.8 ,  58.56,  44.26, 175.91]), 0), (array([ 15.49,   9.21, 102.51,  11.7 ]), 0), (array([198.34,   9.03, 137.  , 154.47]), 0), (array([50.4 ,  5.75, 20.7 , 17.81]), 0), (array([13.46,  8.5 , 27.39, 27.11]), 0), (array([13.74,  2.94,  9.58,  5.37]), 0), (array([208.51,   8.33, 107.77,  89.12]), 0), (array([10.91,  4.95, 18.73, 44.7 ]), 0), (array([13.33,  4.14, 43.38, 35.52]), 0), (array([33.45,  6.82, 24.29, 35.87]), 0), (array([21.33,  6.36, 21.98, 16.61]), 0)]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.array([x for x, y in data])\n",
    "y_out = np.array([y for x, y in data])\n",
    "output = np.array([[0,1] if y == 1 else [1,0] for x, y in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1480.3 ,   38.09,  109.95,   97.51],\n",
       "       [ 116.75,  327.01,  244.69,   82.27],\n",
       "       [  14.3 ,  131.63,  116.75,  114.43],\n",
       "       [ 555.57,  144.03,  278.66,  223.63],\n",
       "       [  29.67,   15.03,  391.51,   66.69],\n",
       "       [  17.46,   25.28,   66.69,   62.8 ],\n",
       "       [  56.26,    8.41,  149.9 ,   25.79],\n",
       "       [   8.67,    3.53,   15.33,   20.7 ],\n",
       "       [  17.99,    8.25,   31.19,   80.64],\n",
       "       [  57.97,   14.59,  149.9 ,   43.82],\n",
       "       [  93.69,   18.54,  219.2 ,   40.85],\n",
       "       [ 105.64,  259.82,  137.  ,   33.78],\n",
       "       [   8.08,   11.02,  167.34,  162.39],\n",
       "       [  43.38,    9.03,   56.83,   36.6 ],\n",
       "       [   2.97,    3.16,   41.68,    4.22],\n",
       "       [   6.36,    4.81,    4.06,    5.05],\n",
       "       [  31.82,   22.87,  157.59,   29.37],\n",
       "       [  16.12,   15.8 ,   78.26,   92.76],\n",
       "       [  79.04,   12.43,   60.34,   42.52],\n",
       "       [  18.73,   20.49,   68.72,   23.81],\n",
       "       [  50.4 ,   18.54,  131.63,   45.6 ],\n",
       "       [ 104.58,   28.79,  170.72,  165.67],\n",
       "       [  63.43,   23.1 ,   66.02,   44.26],\n",
       "       [   2.97,    3.6 ,   50.91,    6.49],\n",
       "       [  54.05,    6.11,   94.63,   14.3 ],\n",
       "       [  72.97,   32.14,   88.23,   24.05],\n",
       "       [  64.07,   68.72,  156.02,  265.07],\n",
       "       [ 126.47,   14.15,  107.77,   24.05],\n",
       "       [   8.41,    5.81,    4.53,   29.37],\n",
       "       [  15.49,   21.33,  114.43,   97.51],\n",
       "       [   3.39,    8.94,   56.26,   13.2 ],\n",
       "       [  29.67,    8.5 ,   64.72,   55.15],\n",
       "       [  22.42,   11.36,  127.74,   33.12],\n",
       "       [  11.7 ,   11.02,  208.51,   40.04],\n",
       "       [  21.76,   39.65,   22.87,   29.08],\n",
       "       [  13.07,    6.49,   45.15,   32.14],\n",
       "       [  53.52,   10.18,  347.23,  101.49],\n",
       "       [ 561.16,   30.57,  116.75,   82.27],\n",
       "       [   8.41,   13.2 ,  126.47,   59.74],\n",
       "       [   8.41,    6.42,   75.94,   14.88],\n",
       "       [ 184.93,   16.78,  146.94,   83.93],\n",
       "       [ 354.25,   16.44,   39.25,   67.36],\n",
       "       [  26.84,   13.87,   34.12,   31.19],\n",
       "       [  14.15,   27.66,  130.32,  135.64],\n",
       "       [  19.49,   37.34,  120.3 ,  194.42],\n",
       "       [  53.52,   57.97,   54.05,  165.67],\n",
       "       [   2.61,    3.94,   28.79,    7.77],\n",
       "       [  26.84,    3.35,   59.15,    3.78],\n",
       "       [  66.69,   19.11,  109.95,   57.97],\n",
       "       [  11.25,    3.9 ,    5.37,   12.18],\n",
       "       [   3.13,    6.42,   11.25,    5.16],\n",
       "       [   5.99,    4.81,    8.58,   12.68],\n",
       "       [  53.52,    6.17,  311.06,  131.63],\n",
       "       [  22.65,   18.54,   55.15,  162.39],\n",
       "       [  24.29,    3.46,    7.92,    7.77],\n",
       "       [  22.87,    3.46,   11.25,    6.11],\n",
       "       [   9.87,    5.37,   70.11,   24.53],\n",
       "       [  44.7 ,   14.15,  247.15,  146.94],\n",
       "       [ 206.44,    6.23,   48.42,   90.92],\n",
       "       [  14.88,   16.12,   13.33,   44.7 ],\n",
       "       [  31.82,    8.  ,   42.52,   59.74],\n",
       "       [   5.99,    1.99,    2.29,   15.18],\n",
       "       [  27.11,    8.58,   14.73,   75.19],\n",
       "       [   9.3 ,    2.53,   37.71,   39.25],\n",
       "       [  13.2 ,    1.55,   43.82,    9.3 ],\n",
       "       [   7.03,   11.47,   21.76,   31.82],\n",
       "       [  10.8 ,   58.56,   44.26,  175.91],\n",
       "       [  15.49,    9.21,  102.51,   11.7 ],\n",
       "       [ 198.34,    9.03,  137.  ,  154.47],\n",
       "       [  50.4 ,    5.75,   20.7 ,   17.81],\n",
       "       [  13.46,    8.5 ,   27.39,   27.11],\n",
       "       [  13.74,    2.94,    9.58,    5.37],\n",
       "       [ 208.51,    8.33,  107.77,   89.12],\n",
       "       [  10.91,    4.95,   18.73,   44.7 ],\n",
       "       [  13.33,    4.14,   43.38,   35.52],\n",
       "       [  33.45,    6.82,   24.29,   35.87],\n",
       "       [  21.33,    6.36,   21.98,   16.61]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdm_model.init_components(np.array(input), np.array(output),\n",
    "                                init_sigma=True, sigma_mult=0.5, super_index=0, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1480.3 ,   38.09,  109.95,   97.51],\n",
       "       [ 116.75,  327.01,  244.69,   82.27],\n",
       "       [  14.3 ,  131.63,  116.75,  114.43],\n",
       "       [ 555.57,  144.03,  278.66,  223.63],\n",
       "       [  29.67,   15.03,  391.51,   66.69],\n",
       "       [  17.46,   25.28,   66.69,   62.8 ],\n",
       "       [  56.26,    8.41,  149.9 ,   25.79],\n",
       "       [   8.67,    3.53,   15.33,   20.7 ],\n",
       "       [  17.99,    8.25,   31.19,   80.64],\n",
       "       [  57.97,   14.59,  149.9 ,   43.82],\n",
       "       [  93.69,   18.54,  219.2 ,   40.85],\n",
       "       [ 105.64,  259.82,  137.  ,   33.78],\n",
       "       [   8.08,   11.02,  167.34,  162.39],\n",
       "       [  43.38,    9.03,   56.83,   36.6 ],\n",
       "       [   2.97,    3.16,   41.68,    4.22],\n",
       "       [   6.36,    4.81,    4.06,    5.05],\n",
       "       [  31.82,   22.87,  157.59,   29.37],\n",
       "       [  16.12,   15.8 ,   78.26,   92.76],\n",
       "       [  79.04,   12.43,   60.34,   42.52],\n",
       "       [  18.73,   20.49,   68.72,   23.81],\n",
       "       [  50.4 ,   18.54,  131.63,   45.6 ],\n",
       "       [ 104.58,   28.79,  170.72,  165.67],\n",
       "       [  63.43,   23.1 ,   66.02,   44.26],\n",
       "       [   2.97,    3.6 ,   50.91,    6.49],\n",
       "       [  54.05,    6.11,   94.63,   14.3 ],\n",
       "       [  72.97,   32.14,   88.23,   24.05],\n",
       "       [  64.07,   68.72,  156.02,  265.07],\n",
       "       [ 126.47,   14.15,  107.77,   24.05],\n",
       "       [   8.41,    5.81,    4.53,   29.37],\n",
       "       [  15.49,   21.33,  114.43,   97.51],\n",
       "       [   3.39,    8.94,   56.26,   13.2 ],\n",
       "       [  29.67,    8.5 ,   64.72,   55.15],\n",
       "       [  22.42,   11.36,  127.74,   33.12],\n",
       "       [  11.7 ,   11.02,  208.51,   40.04],\n",
       "       [  21.76,   39.65,   22.87,   29.08],\n",
       "       [  13.07,    6.49,   45.15,   32.14],\n",
       "       [  53.52,   10.18,  347.23,  101.49],\n",
       "       [ 561.16,   30.57,  116.75,   82.27],\n",
       "       [   8.41,   13.2 ,  126.47,   59.74],\n",
       "       [   8.41,    6.42,   75.94,   14.88],\n",
       "       [ 184.93,   16.78,  146.94,   83.93],\n",
       "       [ 354.25,   16.44,   39.25,   67.36],\n",
       "       [  26.84,   13.87,   34.12,   31.19],\n",
       "       [  14.15,   27.66,  130.32,  135.64],\n",
       "       [  19.49,   37.34,  120.3 ,  194.42],\n",
       "       [  53.52,   57.97,   54.05,  165.67],\n",
       "       [   2.61,    3.94,   28.79,    7.77],\n",
       "       [  26.84,    3.35,   59.15,    3.78],\n",
       "       [  66.69,   19.11,  109.95,   57.97],\n",
       "       [  11.25,    3.9 ,    5.37,   12.18],\n",
       "       [   3.13,    6.42,   11.25,    5.16],\n",
       "       [   5.99,    4.81,    8.58,   12.68],\n",
       "       [  53.52,    6.17,  311.06,  131.63],\n",
       "       [  22.65,   18.54,   55.15,  162.39],\n",
       "       [  24.29,    3.46,    7.92,    7.77],\n",
       "       [  22.87,    3.46,   11.25,    6.11],\n",
       "       [   9.87,    5.37,   70.11,   24.53],\n",
       "       [  44.7 ,   14.15,  247.15,  146.94],\n",
       "       [ 206.44,    6.23,   48.42,   90.92],\n",
       "       [  14.88,   16.12,   13.33,   44.7 ],\n",
       "       [  31.82,    8.  ,   42.52,   59.74],\n",
       "       [   5.99,    1.99,    2.29,   15.18],\n",
       "       [  27.11,    8.58,   14.73,   75.19],\n",
       "       [   9.3 ,    2.53,   37.71,   39.25],\n",
       "       [  13.2 ,    1.55,   43.82,    9.3 ],\n",
       "       [   7.03,   11.47,   21.76,   31.82],\n",
       "       [  10.8 ,   58.56,   44.26,  175.91],\n",
       "       [  15.49,    9.21,  102.51,   11.7 ],\n",
       "       [ 198.34,    9.03,  137.  ,  154.47],\n",
       "       [  50.4 ,    5.75,   20.7 ,   17.81],\n",
       "       [  13.46,    8.5 ,   27.39,   27.11],\n",
       "       [  13.74,    2.94,    9.58,    5.37],\n",
       "       [ 208.51,    8.33,  107.77,   89.12],\n",
       "       [  10.91,    4.95,   18.73,   44.7 ],\n",
       "       [  13.33,    4.14,   43.38,   35.52],\n",
       "       [  33.45,    6.82,   24.29,   35.87],\n",
       "       [  21.33,    6.36,   21.98,   16.61]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho\n",
      "Tensor(\"IteratorGetNext:0\", shape=(None, 4), dtype=float32)\n",
      "(None, 4)\n",
      "rho2\n",
      "Tensor(\"concat:0\", shape=(None, 1, 5), dtype=float32)\n",
      "(None, 1, 5)\n",
      "mergedddd\n",
      "Tensor(\"einsum/Einsum:0\", shape=(None, 2), dtype=float32)\n",
      "probsss\n",
      "Tensor(\"einsum/Einsum:0\", shape=(None, 2), dtype=float32)\n",
      "(None, 2)\n",
      "rho\n",
      "Tensor(\"IteratorGetNext:0\", shape=(None, 4), dtype=float32)\n",
      "(None, 4)\n",
      "rho2\n",
      "Tensor(\"kdm_sequential_joint_class_model_1/concat:0\", shape=(None, 1, 5), dtype=float32)\n",
      "(None, 1, 5)\n",
      "mergedddd\n",
      "Tensor(\"kdm_sequential_joint_class_model_1/einsum/Einsum:0\", shape=(None, 2), dtype=float32)\n",
      "probsss\n",
      "Tensor(\"kdm_sequential_joint_class_model_1/einsum/Einsum:0\", shape=(None, 2), dtype=float32)\n",
      "(None, 2)\n",
      "rho\n",
      "Tensor(\"IteratorGetNext:0\", shape=(None, 4), dtype=float32)\n",
      "(None, 4)\n",
      "rho2\n",
      "Tensor(\"kdm_sequential_joint_class_model_1/concat:0\", shape=(None, 1, 5), dtype=float32)\n",
      "(None, 1, 5)\n",
      "mergedddd\n",
      "Tensor(\"kdm_sequential_joint_class_model_1/einsum/Einsum:0\", shape=(None, 2), dtype=float32)\n",
      "probsss\n",
      "Tensor(\"kdm_sequential_joint_class_model_1/einsum/Einsum:0\", shape=(None, 2), dtype=float32)\n",
      "(None, 2)\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4964 - sparse_categorical_accuracy: 0.8037  \n"
     ]
    }
   ],
   "source": [
    "check_1 = kdm_model.evaluate(np.array(input), np.array(y_out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Dataset loss: 0.5318797826766968\n",
      "Full Dataset accuracy: 0.7792207598686218\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Full Dataset loss:', check_1[0])\n",
    "print('Full Dataset accuracy:', check_1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2s/yq898nms72b5qxqbwz_hx8j80000gn/T/ipykernel_6579/3391731745.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  combined_y = np.array([[y, [0,1]] if y == 1 else [y, [1,0]] for x, y in data])\n"
     ]
    }
   ],
   "source": [
    "combined_y = np.array([[y, [0,1]] if y == 1 else [y, [1,0]] for x, y in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    input, combined_y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoded_size = 4\n",
    "dim_y = 2\n",
    "encoder = keras.layers.Identity()\n",
    "n_comp = 69\n",
    "sequences = [\n",
    "    {\n",
    "        'type': 'merge'\n",
    "    },\n",
    "    ]\n",
    "kdm_model = KDMSequentialJointClassModel(encoded_size=encoded_size,\n",
    "                                         dim_y=dim_y,\n",
    "                                         encoder=encoder,\n",
    "                                         n_comp=n_comp,\n",
    "                                         sequences=sequences,\n",
    "                                         sigma=0.5)\n",
    "\n",
    "kdm_model.compile(optimizer=optimizers.Adam(learning_rate=5e-7),\n",
    "                  loss=losses.sparse_categorical_crossentropy,\n",
    "                  metrics=[metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [0, list([1, 0])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [0, list([1, 0])],\n",
       "       [0, list([1, 0])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])]], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_out = np.array([y[1] for y in y_train])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdm_model.init_components(np.array(X_train), np.array(real_out),\n",
    "                                init_sigma=True, sigma_mult=0.5, super_index=0, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1480.3 ,   38.09,  109.95,   97.51],\n",
       "       [ 116.75,  327.01,  244.69,   82.27],\n",
       "       [  14.3 ,  131.63,  116.75,  114.43],\n",
       "       [ 555.57,  144.03,  278.66,  223.63],\n",
       "       [  29.67,   15.03,  391.51,   66.69],\n",
       "       [  17.46,   25.28,   66.69,   62.8 ],\n",
       "       [  56.26,    8.41,  149.9 ,   25.79],\n",
       "       [   8.67,    3.53,   15.33,   20.7 ],\n",
       "       [  17.99,    8.25,   31.19,   80.64],\n",
       "       [  57.97,   14.59,  149.9 ,   43.82],\n",
       "       [  93.69,   18.54,  219.2 ,   40.85],\n",
       "       [ 105.64,  259.82,  137.  ,   33.78],\n",
       "       [   8.08,   11.02,  167.34,  162.39],\n",
       "       [  43.38,    9.03,   56.83,   36.6 ],\n",
       "       [   2.97,    3.16,   41.68,    4.22],\n",
       "       [   6.36,    4.81,    4.06,    5.05],\n",
       "       [  31.82,   22.87,  157.59,   29.37],\n",
       "       [  16.12,   15.8 ,   78.26,   92.76],\n",
       "       [  79.04,   12.43,   60.34,   42.52],\n",
       "       [  18.73,   20.49,   68.72,   23.81],\n",
       "       [  50.4 ,   18.54,  131.63,   45.6 ],\n",
       "       [ 104.58,   28.79,  170.72,  165.67],\n",
       "       [  63.43,   23.1 ,   66.02,   44.26],\n",
       "       [   2.97,    3.6 ,   50.91,    6.49],\n",
       "       [  54.05,    6.11,   94.63,   14.3 ],\n",
       "       [  72.97,   32.14,   88.23,   24.05],\n",
       "       [  64.07,   68.72,  156.02,  265.07],\n",
       "       [ 126.47,   14.15,  107.77,   24.05],\n",
       "       [   8.41,    5.81,    4.53,   29.37],\n",
       "       [  15.49,   21.33,  114.43,   97.51],\n",
       "       [   3.39,    8.94,   56.26,   13.2 ],\n",
       "       [  29.67,    8.5 ,   64.72,   55.15],\n",
       "       [  22.42,   11.36,  127.74,   33.12],\n",
       "       [  11.7 ,   11.02,  208.51,   40.04],\n",
       "       [  21.76,   39.65,   22.87,   29.08],\n",
       "       [  13.07,    6.49,   45.15,   32.14],\n",
       "       [  53.52,   10.18,  347.23,  101.49],\n",
       "       [ 561.16,   30.57,  116.75,   82.27],\n",
       "       [   8.41,   13.2 ,  126.47,   59.74],\n",
       "       [   8.41,    6.42,   75.94,   14.88],\n",
       "       [ 184.93,   16.78,  146.94,   83.93],\n",
       "       [ 354.25,   16.44,   39.25,   67.36],\n",
       "       [  26.84,   13.87,   34.12,   31.19],\n",
       "       [  14.15,   27.66,  130.32,  135.64],\n",
       "       [  19.49,   37.34,  120.3 ,  194.42],\n",
       "       [  53.52,   57.97,   54.05,  165.67],\n",
       "       [   2.61,    3.94,   28.79,    7.77],\n",
       "       [  26.84,    3.35,   59.15,    3.78],\n",
       "       [  66.69,   19.11,  109.95,   57.97],\n",
       "       [  11.25,    3.9 ,    5.37,   12.18],\n",
       "       [   3.13,    6.42,   11.25,    5.16],\n",
       "       [   5.99,    4.81,    8.58,   12.68],\n",
       "       [  53.52,    6.17,  311.06,  131.63],\n",
       "       [  22.65,   18.54,   55.15,  162.39],\n",
       "       [  24.29,    3.46,    7.92,    7.77],\n",
       "       [  22.87,    3.46,   11.25,    6.11],\n",
       "       [   9.87,    5.37,   70.11,   24.53],\n",
       "       [  44.7 ,   14.15,  247.15,  146.94],\n",
       "       [ 206.44,    6.23,   48.42,   90.92],\n",
       "       [  14.88,   16.12,   13.33,   44.7 ],\n",
       "       [  31.82,    8.  ,   42.52,   59.74],\n",
       "       [   5.99,    1.99,    2.29,   15.18],\n",
       "       [  27.11,    8.58,   14.73,   75.19],\n",
       "       [   9.3 ,    2.53,   37.71,   39.25],\n",
       "       [  13.2 ,    1.55,   43.82,    9.3 ],\n",
       "       [   7.03,   11.47,   21.76,   31.82],\n",
       "       [  10.8 ,   58.56,   44.26,  175.91],\n",
       "       [  15.49,    9.21,  102.51,   11.7 ],\n",
       "       [ 198.34,    9.03,  137.  ,  154.47],\n",
       "       [  50.4 ,    5.75,   20.7 ,   17.81],\n",
       "       [  13.46,    8.5 ,   27.39,   27.11],\n",
       "       [  13.74,    2.94,    9.58,    5.37],\n",
       "       [ 208.51,    8.33,  107.77,   89.12],\n",
       "       [  10.91,    4.95,   18.73,   44.7 ],\n",
       "       [  13.33,    4.14,   43.38,   35.52],\n",
       "       [  33.45,    6.82,   24.29,   35.87],\n",
       "       [  21.33,    6.36,   21.98,   16.61]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho\n",
      "Tensor(\"IteratorGetNext:0\", shape=(None, 4), dtype=float32)\n",
      "(None, 4)\n",
      "rho2\n",
      "Tensor(\"concat:0\", shape=(None, 1, 5), dtype=float32)\n",
      "(None, 1, 5)\n",
      "rho\n",
      "Tensor(\"IteratorGetNext:0\", shape=(None, 4), dtype=float32)\n",
      "(None, 4)\n",
      "rho2\n",
      "Tensor(\"kdm_sequential_joint_class_model_1_1/concat:0\", shape=(None, 1, 5), dtype=float32)\n",
      "(None, 1, 5)\n",
      "rho\n",
      "Tensor(\"IteratorGetNext:0\", shape=(None, 4), dtype=float32)\n",
      "(None, 4)\n",
      "rho2\n",
      "Tensor(\"kdm_sequential_joint_class_model_1_1/concat:0\", shape=(None, 1, 5), dtype=float32)\n",
      "(None, 1, 5)\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4766 - sparse_categorical_accuracy: 0.7841  \n"
     ]
    }
   ],
   "source": [
    "check_full = kdm_model.evaluate(np.array(input), np.array(y_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Dataset loss: 0.5080514550209045\n",
      "Full Dataset accuracy: 0.7792207598686218\n"
     ]
    }
   ],
   "source": [
    "print('Full Dataset loss:', check_full[0])\n",
    "print('Full Dataset accuracy:', check_full[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6931 - sparse_categorical_accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "check_test = kdm_model.evaluate(np.array(X_test), np.array([y[0] for y in y_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6931471824645996\n",
      "Test accuracy: 0.375\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', check_test[0])\n",
    "print('Test accuracy:', check_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6901 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.6900 - sparse_categorical_accuracy: 0.7748 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 0.6900 - sparse_categorical_accuracy: 0.7734 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 0.6904 - sparse_categorical_accuracy: 0.7404 - val_loss: 0.6990 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - loss: 0.6896 - sparse_categorical_accuracy: 0.8085 - val_loss: 0.6990 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 0.6908 - sparse_categorical_accuracy: 0.7035 - val_loss: 0.6990 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 0.6895 - sparse_categorical_accuracy: 0.8142 - val_loss: 0.6990 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 0.6906 - sparse_categorical_accuracy: 0.7194 - val_loss: 0.6991 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.6896 - sparse_categorical_accuracy: 0.8037 - val_loss: 0.6991 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - loss: 0.6891 - sparse_categorical_accuracy: 0.8388 - val_loss: 0.6991 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 11/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.6904 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.6992 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 12/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 0.6901 - sparse_categorical_accuracy: 0.7551 - val_loss: 0.6992 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 13/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 0.6903 - sparse_categorical_accuracy: 0.7351 - val_loss: 0.6992 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 14/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 0.6898 - sparse_categorical_accuracy: 0.7803 - val_loss: 0.6992 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 15/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 0.6898 - sparse_categorical_accuracy: 0.7733 - val_loss: 0.6993 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 16/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - loss: 0.6895 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.6993 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 17/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6913 - sparse_categorical_accuracy: 0.6536 - val_loss: 0.6993 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 18/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 0.6898 - sparse_categorical_accuracy: 0.7725 - val_loss: 0.6994 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 19/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 0.6903 - sparse_categorical_accuracy: 0.7330 - val_loss: 0.6994 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 20/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 0.6905 - sparse_categorical_accuracy: 0.7167 - val_loss: 0.6994 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 21/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 0.6902 - sparse_categorical_accuracy: 0.7391 - val_loss: 0.6994 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 22/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 0.6899 - sparse_categorical_accuracy: 0.7569 - val_loss: 0.6995 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 23/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 0.6905 - sparse_categorical_accuracy: 0.7078 - val_loss: 0.6995 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 24/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 0.6896 - sparse_categorical_accuracy: 0.7832 - val_loss: 0.6995 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 25/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 0.6902 - sparse_categorical_accuracy: 0.7359 - val_loss: 0.6996 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 26/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 0.6897 - sparse_categorical_accuracy: 0.7750 - val_loss: 0.6996 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 27/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.6909 - sparse_categorical_accuracy: 0.6790 - val_loss: 0.6996 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 28/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 0.6897 - sparse_categorical_accuracy: 0.7657 - val_loss: 0.6996 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 29/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 0.6892 - sparse_categorical_accuracy: 0.8037 - val_loss: 0.6997 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 30/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.6891 - sparse_categorical_accuracy: 0.8125 - val_loss: 0.6997 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 31/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.6896 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.6997 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 32/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 0.6891 - sparse_categorical_accuracy: 0.8095 - val_loss: 0.6997 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 33/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - loss: 0.6891 - sparse_categorical_accuracy: 0.8087 - val_loss: 0.6998 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 34/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - loss: 0.6898 - sparse_categorical_accuracy: 0.7563 - val_loss: 0.6998 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 35/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 0.6905 - sparse_categorical_accuracy: 0.7016 - val_loss: 0.6998 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 36/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 0.6901 - sparse_categorical_accuracy: 0.7317 - val_loss: 0.6999 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 37/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - loss: 0.6892 - sparse_categorical_accuracy: 0.7940 - val_loss: 0.6999 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 38/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - loss: 0.6904 - sparse_categorical_accuracy: 0.7077 - val_loss: 0.6999 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 39/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6894 - sparse_categorical_accuracy: 0.7809 - val_loss: 0.6999 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 40/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.6903 - sparse_categorical_accuracy: 0.7141 - val_loss: 0.7000 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 41/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.6905 - sparse_categorical_accuracy: 0.6923 - val_loss: 0.7000 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 42/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 0.6895 - sparse_categorical_accuracy: 0.7695 - val_loss: 0.7000 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 43/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.6890 - sparse_categorical_accuracy: 0.8064 - val_loss: 0.7001 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 44/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 0.6896 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.7001 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 45/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - loss: 0.6905 - sparse_categorical_accuracy: 0.6906 - val_loss: 0.7001 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 46/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 0.6890 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.7001 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 47/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 0.6884 - sparse_categorical_accuracy: 0.8439 - val_loss: 0.7002 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 48/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - loss: 0.6894 - sparse_categorical_accuracy: 0.7722 - val_loss: 0.7002 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 49/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 0.6900 - sparse_categorical_accuracy: 0.7242 - val_loss: 0.7002 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 50/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 0.6901 - sparse_categorical_accuracy: 0.7167 - val_loss: 0.7003 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 51/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 0.6899 - sparse_categorical_accuracy: 0.7331 - val_loss: 0.7003 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 52/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 0.6894 - sparse_categorical_accuracy: 0.7617 - val_loss: 0.7003 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 53/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6895 - sparse_categorical_accuracy: 0.7582 - val_loss: 0.7003 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 54/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 0.6904 - sparse_categorical_accuracy: 0.6915 - val_loss: 0.7004 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 55/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 0.6890 - sparse_categorical_accuracy: 0.7866 - val_loss: 0.7004 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 56/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 0.6887 - sparse_categorical_accuracy: 0.8080 - val_loss: 0.7004 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 57/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 0.6905 - sparse_categorical_accuracy: 0.6845 - val_loss: 0.7005 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 58/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 0.6898 - sparse_categorical_accuracy: 0.7329 - val_loss: 0.7005 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 59/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 0.6895 - sparse_categorical_accuracy: 0.7532 - val_loss: 0.7005 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 60/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 0.6903 - sparse_categorical_accuracy: 0.6965 - val_loss: 0.7005 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 61/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 0.6903 - sparse_categorical_accuracy: 0.6927 - val_loss: 0.7006 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 62/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 0.6887 - sparse_categorical_accuracy: 0.7999 - val_loss: 0.7006 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 63/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 0.6887 - sparse_categorical_accuracy: 0.8040 - val_loss: 0.7006 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 64/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.6892 - sparse_categorical_accuracy: 0.7640 - val_loss: 0.7007 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 65/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 0.6901 - sparse_categorical_accuracy: 0.7051 - val_loss: 0.7007 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 66/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 0.6902 - sparse_categorical_accuracy: 0.6966 - val_loss: 0.7007 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 67/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - loss: 0.6899 - sparse_categorical_accuracy: 0.7163 - val_loss: 0.7007 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 68/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.6895 - sparse_categorical_accuracy: 0.7453 - val_loss: 0.7008 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 69/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 0.6899 - sparse_categorical_accuracy: 0.7158 - val_loss: 0.7008 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 70/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 0.6891 - sparse_categorical_accuracy: 0.7644 - val_loss: 0.7008 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 71/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 0.6891 - sparse_categorical_accuracy: 0.7650 - val_loss: 0.7009 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 72/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 0.6904 - sparse_categorical_accuracy: 0.6838 - val_loss: 0.7009 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 73/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 0.6885 - sparse_categorical_accuracy: 0.8008 - val_loss: 0.7009 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 74/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 0.6882 - sparse_categorical_accuracy: 0.8194 - val_loss: 0.7009 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 75/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 0.6887 - sparse_categorical_accuracy: 0.7884 - val_loss: 0.7010 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 76/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 0.6899 - sparse_categorical_accuracy: 0.7087 - val_loss: 0.7010 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 77/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.6909 - sparse_categorical_accuracy: 0.6459 - val_loss: 0.7010 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 78/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - loss: 0.6905 - sparse_categorical_accuracy: 0.6722 - val_loss: 0.7011 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 79/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 0.6885 - sparse_categorical_accuracy: 0.7942 - val_loss: 0.7011 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 80/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 0.6892 - sparse_categorical_accuracy: 0.7522 - val_loss: 0.7011 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 81/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.6887 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.7011 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 82/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 0.6904 - sparse_categorical_accuracy: 0.6743 - val_loss: 0.7012 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 83/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 0.6887 - sparse_categorical_accuracy: 0.7784 - val_loss: 0.7012 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 84/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.6884 - sparse_categorical_accuracy: 0.7977 - val_loss: 0.7012 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 85/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - loss: 0.6902 - sparse_categorical_accuracy: 0.6829 - val_loss: 0.7013 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 86/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 0.6898 - sparse_categorical_accuracy: 0.7065 - val_loss: 0.7013 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 87/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 0.6884 - sparse_categorical_accuracy: 0.7962 - val_loss: 0.7013 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 88/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 0.6903 - sparse_categorical_accuracy: 0.6770 - val_loss: 0.7013 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 89/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.6893 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.7014 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 90/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 0.6881 - sparse_categorical_accuracy: 0.8103 - val_loss: 0.7014 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 91/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6888 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.7014 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 92/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 0.6893 - sparse_categorical_accuracy: 0.7335 - val_loss: 0.7015 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 93/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 0.6879 - sparse_categorical_accuracy: 0.8190 - val_loss: 0.7015 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 94/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - loss: 0.6879 - sparse_categorical_accuracy: 0.8186 - val_loss: 0.7015 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 95/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 0.6902 - sparse_categorical_accuracy: 0.6814 - val_loss: 0.7015 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 96/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 0.6890 - sparse_categorical_accuracy: 0.7502 - val_loss: 0.7016 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 97/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 0.6898 - sparse_categorical_accuracy: 0.7005 - val_loss: 0.7016 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 98/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - loss: 0.6885 - sparse_categorical_accuracy: 0.7791 - val_loss: 0.7016 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 99/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 0.6874 - sparse_categorical_accuracy: 0.8396 - val_loss: 0.7017 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 100/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 0.6900 - sparse_categorical_accuracy: 0.6875 - val_loss: 0.7017 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 101/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 0.6892 - sparse_categorical_accuracy: 0.7353 - val_loss: 0.7017 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 102/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 0.6891 - sparse_categorical_accuracy: 0.7364 - val_loss: 0.7017 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 103/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 0.6892 - sparse_categorical_accuracy: 0.7348 - val_loss: 0.7018 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 104/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 0.6875 - sparse_categorical_accuracy: 0.8310 - val_loss: 0.7018 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 105/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 0.6905 - sparse_categorical_accuracy: 0.6561 - val_loss: 0.7018 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 106/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 0.6893 - sparse_categorical_accuracy: 0.7259 - val_loss: 0.7019 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 107/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 0.6905 - sparse_categorical_accuracy: 0.6533 - val_loss: 0.7019 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 108/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6882 - sparse_categorical_accuracy: 0.7888 - val_loss: 0.7019 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 109/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 0.6880 - sparse_categorical_accuracy: 0.7990 - val_loss: 0.7019 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 110/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 0.6890 - sparse_categorical_accuracy: 0.7405 - val_loss: 0.7020 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 111/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 0.6883 - sparse_categorical_accuracy: 0.7772 - val_loss: 0.7020 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 112/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 0.6880 - sparse_categorical_accuracy: 0.7929 - val_loss: 0.7020 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 113/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 0.6898 - sparse_categorical_accuracy: 0.6932 - val_loss: 0.7021 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 114/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 0.6885 - sparse_categorical_accuracy: 0.7620 - val_loss: 0.7021 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 115/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 0.6891 - sparse_categorical_accuracy: 0.7308 - val_loss: 0.7021 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 116/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 0.6891 - sparse_categorical_accuracy: 0.7285 - val_loss: 0.7021 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 117/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.6875 - sparse_categorical_accuracy: 0.8164 - val_loss: 0.7022 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 118/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 0.6890 - sparse_categorical_accuracy: 0.7308 - val_loss: 0.7022 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 119/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 0.6905 - sparse_categorical_accuracy: 0.6505 - val_loss: 0.7022 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 120/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 0.6877 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.7023 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 121/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 0.6898 - sparse_categorical_accuracy: 0.6875 - val_loss: 0.7023 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 122/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.6884 - sparse_categorical_accuracy: 0.7634 - val_loss: 0.7023 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 123/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 0.6891 - sparse_categorical_accuracy: 0.7227 - val_loss: 0.7023 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 124/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6883 - sparse_categorical_accuracy: 0.7693 - val_loss: 0.7024 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 125/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 0.6873 - sparse_categorical_accuracy: 0.8224 - val_loss: 0.7024 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 126/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 0.6876 - sparse_categorical_accuracy: 0.8017 - val_loss: 0.7024 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 127/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - loss: 0.6891 - sparse_categorical_accuracy: 0.7236 - val_loss: 0.7025 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 128/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6891 - sparse_categorical_accuracy: 0.7210 - val_loss: 0.7025 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 129/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 0.6884 - sparse_categorical_accuracy: 0.7579 - val_loss: 0.7025 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 130/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 0.6875 - sparse_categorical_accuracy: 0.8067 - val_loss: 0.7025 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 131/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 0.6876 - sparse_categorical_accuracy: 0.8006 - val_loss: 0.7026 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 132/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 0.6877 - sparse_categorical_accuracy: 0.7925 - val_loss: 0.7026 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 133/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 0.6884 - sparse_categorical_accuracy: 0.7558 - val_loss: 0.7026 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 134/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 0.6884 - sparse_categorical_accuracy: 0.7546 - val_loss: 0.7027 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 135/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 0.6874 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.7027 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 136/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.6888 - sparse_categorical_accuracy: 0.7322 - val_loss: 0.7027 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 137/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.6879 - sparse_categorical_accuracy: 0.7762 - val_loss: 0.7028 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 138/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 0.6872 - sparse_categorical_accuracy: 0.8117 - val_loss: 0.7028 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 139/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 0.6880 - sparse_categorical_accuracy: 0.7716 - val_loss: 0.7028 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 140/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6877 - sparse_categorical_accuracy: 0.7864 - val_loss: 0.7028 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 141/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 0.6882 - sparse_categorical_accuracy: 0.7566 - val_loss: 0.7029 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 142/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 0.6863 - sparse_categorical_accuracy: 0.8586 - val_loss: 0.7029 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 143/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 0.6869 - sparse_categorical_accuracy: 0.8217 - val_loss: 0.7029 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 144/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.6889 - sparse_categorical_accuracy: 0.7187 - val_loss: 0.7030 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 145/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 0.6878 - sparse_categorical_accuracy: 0.7769 - val_loss: 0.7030 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 146/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.6874 - sparse_categorical_accuracy: 0.7948 - val_loss: 0.7030 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 147/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 0.6879 - sparse_categorical_accuracy: 0.7679 - val_loss: 0.7030 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 148/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 0.6874 - sparse_categorical_accuracy: 0.7923 - val_loss: 0.7031 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 149/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 0.6877 - sparse_categorical_accuracy: 0.7804 - val_loss: 0.7031 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 150/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 0.6878 - sparse_categorical_accuracy: 0.7716 - val_loss: 0.7031 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 151/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 0.6871 - sparse_categorical_accuracy: 0.8081 - val_loss: 0.7031 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 152/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - loss: 0.6879 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.7032 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 153/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 0.6880 - sparse_categorical_accuracy: 0.7586 - val_loss: 0.7032 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 154/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - loss: 0.6853 - sparse_categorical_accuracy: 0.8922 - val_loss: 0.7032 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 155/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6875 - sparse_categorical_accuracy: 0.7842 - val_loss: 0.7033 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 156/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 0.6879 - sparse_categorical_accuracy: 0.7640 - val_loss: 0.7033 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 157/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 0.6877 - sparse_categorical_accuracy: 0.7716 - val_loss: 0.7033 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 158/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 0.6893 - sparse_categorical_accuracy: 0.6943 - val_loss: 0.7033 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 159/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 0.6883 - sparse_categorical_accuracy: 0.7397 - val_loss: 0.7034 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 160/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 0.6871 - sparse_categorical_accuracy: 0.8013 - val_loss: 0.7034 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 161/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 0.6871 - sparse_categorical_accuracy: 0.7984 - val_loss: 0.7034 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 162/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.6875 - sparse_categorical_accuracy: 0.7773 - val_loss: 0.7035 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 163/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 0.6880 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.7035 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 164/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.6885 - sparse_categorical_accuracy: 0.7291 - val_loss: 0.7035 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 165/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 0.6870 - sparse_categorical_accuracy: 0.8024 - val_loss: 0.7035 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 166/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 0.6868 - sparse_categorical_accuracy: 0.8088 - val_loss: 0.7036 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 167/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - loss: 0.6879 - sparse_categorical_accuracy: 0.7541 - val_loss: 0.7036 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 168/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6880 - sparse_categorical_accuracy: 0.7505 - val_loss: 0.7036 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 169/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - loss: 0.6881 - sparse_categorical_accuracy: 0.7452 - val_loss: 0.7037 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 170/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 0.6875 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.7037 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 171/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - loss: 0.6908 - sparse_categorical_accuracy: 0.6154 - val_loss: 0.7037 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 172/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 0.6897 - sparse_categorical_accuracy: 0.6680 - val_loss: 0.7037 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 173/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 0.6857 - sparse_categorical_accuracy: 0.8563 - val_loss: 0.7038 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 174/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 0.6868 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.7038 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 175/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.6867 - sparse_categorical_accuracy: 0.8061 - val_loss: 0.7038 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 176/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 0.6864 - sparse_categorical_accuracy: 0.8179 - val_loss: 0.7039 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 177/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 0.6873 - sparse_categorical_accuracy: 0.7766 - val_loss: 0.7039 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 178/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 0.6859 - sparse_categorical_accuracy: 0.8400 - val_loss: 0.7039 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 179/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 0.6872 - sparse_categorical_accuracy: 0.7780 - val_loss: 0.7039 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 180/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 0.6861 - sparse_categorical_accuracy: 0.8289 - val_loss: 0.7040 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 181/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6882 - sparse_categorical_accuracy: 0.7337 - val_loss: 0.7040 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 182/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 0.6870 - sparse_categorical_accuracy: 0.7854 - val_loss: 0.7040 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 183/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.6864 - sparse_categorical_accuracy: 0.8138 - val_loss: 0.7041 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 184/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 0.6887 - sparse_categorical_accuracy: 0.7091 - val_loss: 0.7041 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 185/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 0.6869 - sparse_categorical_accuracy: 0.7886 - val_loss: 0.7041 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 186/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 0.6898 - sparse_categorical_accuracy: 0.6551 - val_loss: 0.7041 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 187/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 0.6867 - sparse_categorical_accuracy: 0.7993 - val_loss: 0.7042 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 188/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 0.6876 - sparse_categorical_accuracy: 0.7567 - val_loss: 0.7042 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 189/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 0.6886 - sparse_categorical_accuracy: 0.7085 - val_loss: 0.7042 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 190/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 0.6873 - sparse_categorical_accuracy: 0.7699 - val_loss: 0.7043 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 191/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 0.6883 - sparse_categorical_accuracy: 0.7227 - val_loss: 0.7043 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 192/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 0.6883 - sparse_categorical_accuracy: 0.7224 - val_loss: 0.7043 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 193/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 0.6884 - sparse_categorical_accuracy: 0.7150 - val_loss: 0.7043 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 194/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6878 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.7044 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 195/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 0.6879 - sparse_categorical_accuracy: 0.7385 - val_loss: 0.7044 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 196/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - loss: 0.6872 - sparse_categorical_accuracy: 0.7670 - val_loss: 0.7044 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 197/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 0.6857 - sparse_categorical_accuracy: 0.8366 - val_loss: 0.7045 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 198/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 0.6873 - sparse_categorical_accuracy: 0.7634 - val_loss: 0.7045 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 199/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 0.6860 - sparse_categorical_accuracy: 0.8211 - val_loss: 0.7045 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 200/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 0.6876 - sparse_categorical_accuracy: 0.7465 - val_loss: 0.7045 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 201/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 0.6880 - sparse_categorical_accuracy: 0.7321 - val_loss: 0.7046 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 202/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - loss: 0.6848 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.7046 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 203/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.6862 - sparse_categorical_accuracy: 0.8083 - val_loss: 0.7046 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 204/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - loss: 0.6879 - sparse_categorical_accuracy: 0.7328 - val_loss: 0.7046 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 205/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 0.6875 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.7047 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 206/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 0.6875 - sparse_categorical_accuracy: 0.7505 - val_loss: 0.7047 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 207/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.6868 - sparse_categorical_accuracy: 0.7790 - val_loss: 0.7047 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 208/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 0.6863 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.7048 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 209/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.6860 - sparse_categorical_accuracy: 0.8126 - val_loss: 0.7048 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 210/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 0.6882 - sparse_categorical_accuracy: 0.7169 - val_loss: 0.7048 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 211/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 0.6882 - sparse_categorical_accuracy: 0.7156 - val_loss: 0.7048 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 212/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 0.6890 - sparse_categorical_accuracy: 0.6791 - val_loss: 0.7049 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 213/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 0.6867 - sparse_categorical_accuracy: 0.7796 - val_loss: 0.7049 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 214/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 0.6874 - sparse_categorical_accuracy: 0.7479 - val_loss: 0.7049 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 215/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.6876 - sparse_categorical_accuracy: 0.7376 - val_loss: 0.7050 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 216/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.6873 - sparse_categorical_accuracy: 0.7532 - val_loss: 0.7050 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 217/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 0.6867 - sparse_categorical_accuracy: 0.7746 - val_loss: 0.7050 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 218/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - loss: 0.6870 - sparse_categorical_accuracy: 0.7641 - val_loss: 0.7050 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 219/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6863 - sparse_categorical_accuracy: 0.7917 - val_loss: 0.7051 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 220/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 0.6862 - sparse_categorical_accuracy: 0.7968 - val_loss: 0.7051 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 221/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 0.6867 - sparse_categorical_accuracy: 0.7729 - val_loss: 0.7051 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 222/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 0.6864 - sparse_categorical_accuracy: 0.7872 - val_loss: 0.7052 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 223/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 0.6876 - sparse_categorical_accuracy: 0.7349 - val_loss: 0.7052 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 224/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 0.6865 - sparse_categorical_accuracy: 0.7806 - val_loss: 0.7052 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 225/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 0.6894 - sparse_categorical_accuracy: 0.6584 - val_loss: 0.7052 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 226/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 0.6866 - sparse_categorical_accuracy: 0.7763 - val_loss: 0.7053 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 227/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 0.6896 - sparse_categorical_accuracy: 0.6502 - val_loss: 0.7053 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 228/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 0.6871 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.7053 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 229/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.6868 - sparse_categorical_accuracy: 0.7668 - val_loss: 0.7054 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 230/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 0.6886 - sparse_categorical_accuracy: 0.6884 - val_loss: 0.7054 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 231/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 0.6892 - sparse_categorical_accuracy: 0.6665 - val_loss: 0.7054 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 232/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6873 - sparse_categorical_accuracy: 0.7424 - val_loss: 0.7054 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 233/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 0.6868 - sparse_categorical_accuracy: 0.7610 - val_loss: 0.7055 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 234/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 0.6859 - sparse_categorical_accuracy: 0.7976 - val_loss: 0.7055 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 235/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 0.6874 - sparse_categorical_accuracy: 0.7381 - val_loss: 0.7055 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 236/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 0.6877 - sparse_categorical_accuracy: 0.7256 - val_loss: 0.7056 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 237/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 0.6864 - sparse_categorical_accuracy: 0.7762 - val_loss: 0.7056 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 238/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 0.6871 - sparse_categorical_accuracy: 0.7467 - val_loss: 0.7056 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 239/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 0.6874 - sparse_categorical_accuracy: 0.7337 - val_loss: 0.7056 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 240/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 0.6887 - sparse_categorical_accuracy: 0.6831 - val_loss: 0.7057 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 241/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 0.6859 - sparse_categorical_accuracy: 0.7956 - val_loss: 0.7057 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 242/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 0.6858 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.7057 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 243/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 0.6857 - sparse_categorical_accuracy: 0.8021 - val_loss: 0.7058 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 244/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 0.6849 - sparse_categorical_accuracy: 0.8326 - val_loss: 0.7058 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 245/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6842 - sparse_categorical_accuracy: 0.8581 - val_loss: 0.7058 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 246/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - loss: 0.6861 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.7058 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 247/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - loss: 0.6872 - sparse_categorical_accuracy: 0.7370 - val_loss: 0.7059 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 248/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.6856 - sparse_categorical_accuracy: 0.8011 - val_loss: 0.7059 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 249/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 0.6847 - sparse_categorical_accuracy: 0.8354 - val_loss: 0.7059 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 250/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 0.6883 - sparse_categorical_accuracy: 0.6921 - val_loss: 0.7060 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 251/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 0.6850 - sparse_categorical_accuracy: 0.8238 - val_loss: 0.7060 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 252/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - loss: 0.6871 - sparse_categorical_accuracy: 0.7406 - val_loss: 0.7060 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 253/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 0.6866 - sparse_categorical_accuracy: 0.7581 - val_loss: 0.7060 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 254/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 0.6864 - sparse_categorical_accuracy: 0.7658 - val_loss: 0.7061 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 255/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 0.6840 - sparse_categorical_accuracy: 0.8587 - val_loss: 0.7061 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 256/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.6875 - sparse_categorical_accuracy: 0.7229 - val_loss: 0.7061 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 257/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 0.6857 - sparse_categorical_accuracy: 0.7919 - val_loss: 0.7062 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 258/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 0.6852 - sparse_categorical_accuracy: 0.8110 - val_loss: 0.7062 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 259/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 0.6872 - sparse_categorical_accuracy: 0.7324 - val_loss: 0.7062 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 260/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - loss: 0.6866 - sparse_categorical_accuracy: 0.7565 - val_loss: 0.7062 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 261/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - loss: 0.6875 - sparse_categorical_accuracy: 0.7182 - val_loss: 0.7063 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 262/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 0.6856 - sparse_categorical_accuracy: 0.7921 - val_loss: 0.7063 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 263/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 0.6862 - sparse_categorical_accuracy: 0.7683 - val_loss: 0.7063 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 264/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.6857 - sparse_categorical_accuracy: 0.7887 - val_loss: 0.7064 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 265/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.6877 - sparse_categorical_accuracy: 0.7118 - val_loss: 0.7064 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 266/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 0.6868 - sparse_categorical_accuracy: 0.7454 - val_loss: 0.7064 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 267/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 0.6844 - sparse_categorical_accuracy: 0.8354 - val_loss: 0.7064 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 268/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.6860 - sparse_categorical_accuracy: 0.7741 - val_loss: 0.7065 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 269/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 0.6873 - sparse_categorical_accuracy: 0.7248 - val_loss: 0.7065 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 270/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 0.6860 - sparse_categorical_accuracy: 0.7735 - val_loss: 0.7065 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 271/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.6880 - sparse_categorical_accuracy: 0.6950 - val_loss: 0.7066 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 272/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.6843 - sparse_categorical_accuracy: 0.8366 - val_loss: 0.7066 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 273/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 0.6865 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.7066 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 274/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 0.6835 - sparse_categorical_accuracy: 0.8642 - val_loss: 0.7066 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 275/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.6845 - sparse_categorical_accuracy: 0.8246 - val_loss: 0.7067 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 276/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.6871 - sparse_categorical_accuracy: 0.7281 - val_loss: 0.7067 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 277/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - loss: 0.6846 - sparse_categorical_accuracy: 0.8225 - val_loss: 0.7067 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 278/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - loss: 0.6868 - sparse_categorical_accuracy: 0.7376 - val_loss: 0.7068 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 279/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6857 - sparse_categorical_accuracy: 0.7798 - val_loss: 0.7068 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 280/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 0.6843 - sparse_categorical_accuracy: 0.8312 - val_loss: 0.7068 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 281/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 0.6864 - sparse_categorical_accuracy: 0.7499 - val_loss: 0.7068 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 282/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.6891 - sparse_categorical_accuracy: 0.6520 - val_loss: 0.7069 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 283/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 0.6855 - sparse_categorical_accuracy: 0.7848 - val_loss: 0.7069 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 284/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 0.6861 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.7069 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 285/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.6886 - sparse_categorical_accuracy: 0.6680 - val_loss: 0.7070 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 286/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 0.6851 - sparse_categorical_accuracy: 0.7967 - val_loss: 0.7070 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 287/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.6858 - sparse_categorical_accuracy: 0.7711 - val_loss: 0.7070 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 288/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.6856 - sparse_categorical_accuracy: 0.7756 - val_loss: 0.7070 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 289/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - loss: 0.6869 - sparse_categorical_accuracy: 0.7298 - val_loss: 0.7071 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 290/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 0.6860 - sparse_categorical_accuracy: 0.7612 - val_loss: 0.7071 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 291/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 0.6861 - sparse_categorical_accuracy: 0.7589 - val_loss: 0.7071 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 292/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6863 - sparse_categorical_accuracy: 0.7498 - val_loss: 0.7072 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 293/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.6842 - sparse_categorical_accuracy: 0.8249 - val_loss: 0.7072 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 294/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 0.6868 - sparse_categorical_accuracy: 0.7312 - val_loss: 0.7072 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 295/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 0.6841 - sparse_categorical_accuracy: 0.8259 - val_loss: 0.7072 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 296/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 0.6847 - sparse_categorical_accuracy: 0.8046 - val_loss: 0.7073 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 297/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - loss: 0.6840 - sparse_categorical_accuracy: 0.8301 - val_loss: 0.7073 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 298/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 0.6866 - sparse_categorical_accuracy: 0.7371 - val_loss: 0.7073 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 299/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.6842 - sparse_categorical_accuracy: 0.8224 - val_loss: 0.7074 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 300/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 0.6863 - sparse_categorical_accuracy: 0.7443 - val_loss: 0.7074 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 301/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - loss: 0.6862 - sparse_categorical_accuracy: 0.7504 - val_loss: 0.7074 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 302/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - loss: 0.6877 - sparse_categorical_accuracy: 0.6962 - val_loss: 0.7074 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 303/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.6879 - sparse_categorical_accuracy: 0.6893 - val_loss: 0.7075 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 304/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6878 - sparse_categorical_accuracy: 0.6915 - val_loss: 0.7075 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 305/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.6890 - sparse_categorical_accuracy: 0.6494 - val_loss: 0.7075 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 306/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.6864 - sparse_categorical_accuracy: 0.7403 - val_loss: 0.7076 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 307/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.6863 - sparse_categorical_accuracy: 0.7439 - val_loss: 0.7076 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 308/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.6882 - sparse_categorical_accuracy: 0.6749 - val_loss: 0.7076 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 309/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - loss: 0.6844 - sparse_categorical_accuracy: 0.8090 - val_loss: 0.7076 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 310/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.6867 - sparse_categorical_accuracy: 0.7264 - val_loss: 0.7077 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 311/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.6854 - sparse_categorical_accuracy: 0.7711 - val_loss: 0.7077 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 312/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 0.6836 - sparse_categorical_accuracy: 0.8325 - val_loss: 0.7077 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 313/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 0.6837 - sparse_categorical_accuracy: 0.8300 - val_loss: 0.7078 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 314/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 0.6875 - sparse_categorical_accuracy: 0.6978 - val_loss: 0.7078 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 315/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 0.6854 - sparse_categorical_accuracy: 0.7707 - val_loss: 0.7078 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 316/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 0.6876 - sparse_categorical_accuracy: 0.6950 - val_loss: 0.7078 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 317/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.6876 - sparse_categorical_accuracy: 0.6952 - val_loss: 0.7079 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 318/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 0.6872 - sparse_categorical_accuracy: 0.7074 - val_loss: 0.7079 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 319/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 0.6843 - sparse_categorical_accuracy: 0.8055 - val_loss: 0.7079 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 320/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 0.6863 - sparse_categorical_accuracy: 0.7355 - val_loss: 0.7080 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 321/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.6846 - sparse_categorical_accuracy: 0.7926 - val_loss: 0.7080 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 322/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 0.6870 - sparse_categorical_accuracy: 0.7122 - val_loss: 0.7080 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 323/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.6835 - sparse_categorical_accuracy: 0.8316 - val_loss: 0.7080 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 324/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.6860 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.7081 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 325/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.6853 - sparse_categorical_accuracy: 0.7687 - val_loss: 0.7081 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 326/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 0.6833 - sparse_categorical_accuracy: 0.8364 - val_loss: 0.7081 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 327/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6873 - sparse_categorical_accuracy: 0.7004 - val_loss: 0.7082 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 328/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 0.6846 - sparse_categorical_accuracy: 0.7911 - val_loss: 0.7082 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 329/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 0.6850 - sparse_categorical_accuracy: 0.7779 - val_loss: 0.7082 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 330/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 0.6852 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.7082 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 331/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 0.6856 - sparse_categorical_accuracy: 0.7547 - val_loss: 0.7083 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 332/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 0.6849 - sparse_categorical_accuracy: 0.7787 - val_loss: 0.7083 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 333/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.6866 - sparse_categorical_accuracy: 0.7198 - val_loss: 0.7083 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 334/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 0.6847 - sparse_categorical_accuracy: 0.7840 - val_loss: 0.7084 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 335/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.6862 - sparse_categorical_accuracy: 0.7338 - val_loss: 0.7084 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 336/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.6848 - sparse_categorical_accuracy: 0.7782 - val_loss: 0.7084 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 337/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6887 - sparse_categorical_accuracy: 0.6505 - val_loss: 0.7084 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 338/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.6842 - sparse_categorical_accuracy: 0.7974 - val_loss: 0.7085 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 339/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 0.6833 - sparse_categorical_accuracy: 0.8272 - val_loss: 0.7085 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 340/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.6843 - sparse_categorical_accuracy: 0.7942 - val_loss: 0.7085 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 341/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 0.6854 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.7086 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 342/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.6845 - sparse_categorical_accuracy: 0.7863 - val_loss: 0.7086 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 343/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 0.6851 - sparse_categorical_accuracy: 0.7675 - val_loss: 0.7086 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 344/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 0.6840 - sparse_categorical_accuracy: 0.8028 - val_loss: 0.7086 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 345/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - loss: 0.6865 - sparse_categorical_accuracy: 0.7187 - val_loss: 0.7087 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 346/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 0.6845 - sparse_categorical_accuracy: 0.7842 - val_loss: 0.7087 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 347/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.6835 - sparse_categorical_accuracy: 0.8176 - val_loss: 0.7087 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 348/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.6840 - sparse_categorical_accuracy: 0.7986 - val_loss: 0.7088 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 349/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 0.6836 - sparse_categorical_accuracy: 0.8134 - val_loss: 0.7088 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 350/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 0.6848 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.7088 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 351/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.6845 - sparse_categorical_accuracy: 0.7827 - val_loss: 0.7088 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 352/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.6849 - sparse_categorical_accuracy: 0.7677 - val_loss: 0.7089 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 353/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.6854 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.7089 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 354/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.6843 - sparse_categorical_accuracy: 0.7875 - val_loss: 0.7089 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 355/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 0.6842 - sparse_categorical_accuracy: 0.7897 - val_loss: 0.7089 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 356/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 0.6872 - sparse_categorical_accuracy: 0.6927 - val_loss: 0.7090 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 357/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6857 - sparse_categorical_accuracy: 0.7414 - val_loss: 0.7090 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 358/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - loss: 0.6895 - sparse_categorical_accuracy: 0.6196 - val_loss: 0.7090 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 359/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 0.6840 - sparse_categorical_accuracy: 0.7954 - val_loss: 0.7091 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 360/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - loss: 0.6844 - sparse_categorical_accuracy: 0.7792 - val_loss: 0.7091 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 361/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 0.6840 - sparse_categorical_accuracy: 0.7944 - val_loss: 0.7091 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 362/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.6858 - sparse_categorical_accuracy: 0.7343 - val_loss: 0.7091 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 363/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 0.6875 - sparse_categorical_accuracy: 0.6831 - val_loss: 0.7092 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 364/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 0.6862 - sparse_categorical_accuracy: 0.7221 - val_loss: 0.7092 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 365/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6849 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.7092 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 366/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 0.6840 - sparse_categorical_accuracy: 0.7916 - val_loss: 0.7093 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 367/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 0.6865 - sparse_categorical_accuracy: 0.7124 - val_loss: 0.7093 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 368/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 0.6871 - sparse_categorical_accuracy: 0.6940 - val_loss: 0.7093 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 369/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.6868 - sparse_categorical_accuracy: 0.7031 - val_loss: 0.7093 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 370/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 0.6835 - sparse_categorical_accuracy: 0.8040 - val_loss: 0.7094 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 371/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.6862 - sparse_categorical_accuracy: 0.7199 - val_loss: 0.7094 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 372/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 0.6827 - sparse_categorical_accuracy: 0.8282 - val_loss: 0.7094 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 373/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - loss: 0.6848 - sparse_categorical_accuracy: 0.7619 - val_loss: 0.7095 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 374/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 0.6856 - sparse_categorical_accuracy: 0.7364 - val_loss: 0.7095 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 375/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 0.6834 - sparse_categorical_accuracy: 0.8044 - val_loss: 0.7095 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 376/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.6865 - sparse_categorical_accuracy: 0.7082 - val_loss: 0.7095 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 377/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - loss: 0.6842 - sparse_categorical_accuracy: 0.7799 - val_loss: 0.7096 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 378/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 0.6829 - sparse_categorical_accuracy: 0.8184 - val_loss: 0.7096 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 379/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.6854 - sparse_categorical_accuracy: 0.7398 - val_loss: 0.7096 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 380/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 0.6855 - sparse_categorical_accuracy: 0.7377 - val_loss: 0.7097 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 381/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 0.6868 - sparse_categorical_accuracy: 0.6984 - val_loss: 0.7097 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 382/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 0.6866 - sparse_categorical_accuracy: 0.7034 - val_loss: 0.7097 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 383/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 0.6866 - sparse_categorical_accuracy: 0.7027 - val_loss: 0.7097 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 384/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6869 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.7098 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 385/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 0.6827 - sparse_categorical_accuracy: 0.8197 - val_loss: 0.7098 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 386/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.6883 - sparse_categorical_accuracy: 0.6498 - val_loss: 0.7098 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 387/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 0.6857 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.7099 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 388/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - loss: 0.6838 - sparse_categorical_accuracy: 0.7851 - val_loss: 0.7099 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 389/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 0.6851 - sparse_categorical_accuracy: 0.7474 - val_loss: 0.7099 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 390/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.6831 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.7099 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 391/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 0.6845 - sparse_categorical_accuracy: 0.7621 - val_loss: 0.7100 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 392/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 0.6844 - sparse_categorical_accuracy: 0.7658 - val_loss: 0.7100 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 393/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 0.6863 - sparse_categorical_accuracy: 0.7096 - val_loss: 0.7100 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 394/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 0.6893 - sparse_categorical_accuracy: 0.6183 - val_loss: 0.7101 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 395/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6837 - sparse_categorical_accuracy: 0.7863 - val_loss: 0.7101 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 396/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.6854 - sparse_categorical_accuracy: 0.7344 - val_loss: 0.7101 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 397/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 0.6834 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.7101 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 398/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.6849 - sparse_categorical_accuracy: 0.7481 - val_loss: 0.7102 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 399/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.6837 - sparse_categorical_accuracy: 0.7840 - val_loss: 0.7102 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 400/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - loss: 0.6855 - sparse_categorical_accuracy: 0.7289 - val_loss: 0.7102 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 401/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 0.6850 - sparse_categorical_accuracy: 0.7457 - val_loss: 0.7103 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 402/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - loss: 0.6883 - sparse_categorical_accuracy: 0.6477 - val_loss: 0.7103 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 403/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6811 - sparse_categorical_accuracy: 0.8599 - val_loss: 0.7103 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 404/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 0.6847 - sparse_categorical_accuracy: 0.7525 - val_loss: 0.7103 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 405/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 0.6857 - sparse_categorical_accuracy: 0.7226 - val_loss: 0.7104 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 406/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.6840 - sparse_categorical_accuracy: 0.7712 - val_loss: 0.7104 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 407/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - loss: 0.6861 - sparse_categorical_accuracy: 0.7114 - val_loss: 0.7104 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 408/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 0.6841 - sparse_categorical_accuracy: 0.7674 - val_loss: 0.7105 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 409/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 0.6854 - sparse_categorical_accuracy: 0.7296 - val_loss: 0.7105 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 410/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 0.6846 - sparse_categorical_accuracy: 0.7519 - val_loss: 0.7105 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 411/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6849 - sparse_categorical_accuracy: 0.7449 - val_loss: 0.7105 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 412/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.6852 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.7106 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 413/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.6870 - sparse_categorical_accuracy: 0.6824 - val_loss: 0.7106 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 414/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 0.6841 - sparse_categorical_accuracy: 0.7654 - val_loss: 0.7106 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 415/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 0.6830 - sparse_categorical_accuracy: 0.7962 - val_loss: 0.7107 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 416/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 0.6835 - sparse_categorical_accuracy: 0.7825 - val_loss: 0.7107 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 417/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.6841 - sparse_categorical_accuracy: 0.7634 - val_loss: 0.7107 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 418/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.6864 - sparse_categorical_accuracy: 0.6992 - val_loss: 0.7107 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 419/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.6841 - sparse_categorical_accuracy: 0.7633 - val_loss: 0.7108 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 420/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6838 - sparse_categorical_accuracy: 0.7722 - val_loss: 0.7108 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 421/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 0.6846 - sparse_categorical_accuracy: 0.7480 - val_loss: 0.7108 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 422/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 0.6839 - sparse_categorical_accuracy: 0.7694 - val_loss: 0.7109 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 423/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 0.6845 - sparse_categorical_accuracy: 0.7494 - val_loss: 0.7109 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 424/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.6820 - sparse_categorical_accuracy: 0.8214 - val_loss: 0.7109 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 425/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 0.6841 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.7109 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 426/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.6864 - sparse_categorical_accuracy: 0.6965 - val_loss: 0.7110 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 427/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 0.6851 - sparse_categorical_accuracy: 0.7328 - val_loss: 0.7110 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 428/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6817 - sparse_categorical_accuracy: 0.8266 - val_loss: 0.7110 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 429/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 0.6824 - sparse_categorical_accuracy: 0.8081 - val_loss: 0.7111 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 430/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.6818 - sparse_categorical_accuracy: 0.8242 - val_loss: 0.7111 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 431/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 0.6873 - sparse_categorical_accuracy: 0.6695 - val_loss: 0.7111 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 432/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.6838 - sparse_categorical_accuracy: 0.7672 - val_loss: 0.7111 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 433/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 0.6862 - sparse_categorical_accuracy: 0.6992 - val_loss: 0.7112 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 434/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 0.6813 - sparse_categorical_accuracy: 0.8369 - val_loss: 0.7112 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 435/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.6831 - sparse_categorical_accuracy: 0.7864 - val_loss: 0.7112 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 436/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 0.6803 - sparse_categorical_accuracy: 0.8632 - val_loss: 0.7113 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 437/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 0.6828 - sparse_categorical_accuracy: 0.7935 - val_loss: 0.7113 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 438/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.6860 - sparse_categorical_accuracy: 0.7025 - val_loss: 0.7113 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 439/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - loss: 0.6854 - sparse_categorical_accuracy: 0.7203 - val_loss: 0.7114 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 440/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 0.6828 - sparse_categorical_accuracy: 0.7924 - val_loss: 0.7114 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 441/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - loss: 0.6868 - sparse_categorical_accuracy: 0.6803 - val_loss: 0.7114 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 442/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 0.6840 - sparse_categorical_accuracy: 0.7565 - val_loss: 0.7114 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 443/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6825 - sparse_categorical_accuracy: 0.7989 - val_loss: 0.7115 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 444/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 0.6807 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.7115 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 445/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 0.6825 - sparse_categorical_accuracy: 0.7960 - val_loss: 0.7115 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 446/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 0.6839 - sparse_categorical_accuracy: 0.7573 - val_loss: 0.7116 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 447/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 0.6831 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.7116 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 448/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 0.6825 - sparse_categorical_accuracy: 0.7963 - val_loss: 0.7116 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 449/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.6849 - sparse_categorical_accuracy: 0.7286 - val_loss: 0.7116 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 450/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.6856 - sparse_categorical_accuracy: 0.7102 - val_loss: 0.7117 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 451/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.6837 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.7117 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 452/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6822 - sparse_categorical_accuracy: 0.8015 - val_loss: 0.7117 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 453/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 0.6845 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.7118 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 454/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 0.6845 - sparse_categorical_accuracy: 0.7400 - val_loss: 0.7118 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 455/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 0.6831 - sparse_categorical_accuracy: 0.7772 - val_loss: 0.7118 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 456/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.6849 - sparse_categorical_accuracy: 0.7282 - val_loss: 0.7118 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 457/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 0.6817 - sparse_categorical_accuracy: 0.8126 - val_loss: 0.7119 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 458/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 0.6862 - sparse_categorical_accuracy: 0.6920 - val_loss: 0.7119 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 459/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 0.6828 - sparse_categorical_accuracy: 0.7836 - val_loss: 0.7119 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 460/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6829 - sparse_categorical_accuracy: 0.7787 - val_loss: 0.7120 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 461/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 0.6820 - sparse_categorical_accuracy: 0.8037 - val_loss: 0.7120 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 462/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 0.6837 - sparse_categorical_accuracy: 0.7571 - val_loss: 0.7120 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 463/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - loss: 0.6833 - sparse_categorical_accuracy: 0.7691 - val_loss: 0.7120 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 464/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 0.6835 - sparse_categorical_accuracy: 0.7617 - val_loss: 0.7121 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 465/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - loss: 0.6817 - sparse_categorical_accuracy: 0.8103 - val_loss: 0.7121 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 466/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 0.6842 - sparse_categorical_accuracy: 0.7428 - val_loss: 0.7121 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 467/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 0.6870 - sparse_categorical_accuracy: 0.6688 - val_loss: 0.7122 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 468/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.6850 - sparse_categorical_accuracy: 0.7205 - val_loss: 0.7122 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 469/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 0.6827 - sparse_categorical_accuracy: 0.7822 - val_loss: 0.7122 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 470/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 0.6853 - sparse_categorical_accuracy: 0.7132 - val_loss: 0.7122 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 471/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.6819 - sparse_categorical_accuracy: 0.8027 - val_loss: 0.7123 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 472/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 0.6829 - sparse_categorical_accuracy: 0.7756 - val_loss: 0.7123 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 473/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.6833 - sparse_categorical_accuracy: 0.7636 - val_loss: 0.7123 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 474/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 0.6859 - sparse_categorical_accuracy: 0.6962 - val_loss: 0.7124 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 475/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 0.6848 - sparse_categorical_accuracy: 0.7243 - val_loss: 0.7124 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 476/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6830 - sparse_categorical_accuracy: 0.7718 - val_loss: 0.7124 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 477/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 0.6823 - sparse_categorical_accuracy: 0.7881 - val_loss: 0.7124 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 478/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.6824 - sparse_categorical_accuracy: 0.7850 - val_loss: 0.7125 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 479/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.6839 - sparse_categorical_accuracy: 0.7459 - val_loss: 0.7125 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 480/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.6871 - sparse_categorical_accuracy: 0.6614 - val_loss: 0.7125 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 481/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.6850 - sparse_categorical_accuracy: 0.7158 - val_loss: 0.7126 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 482/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 0.6811 - sparse_categorical_accuracy: 0.8188 - val_loss: 0.7126 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 483/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 0.6820 - sparse_categorical_accuracy: 0.7932 - val_loss: 0.7126 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 484/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 0.6808 - sparse_categorical_accuracy: 0.8258 - val_loss: 0.7126 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 485/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6846 - sparse_categorical_accuracy: 0.7257 - val_loss: 0.7127 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 486/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - loss: 0.6809 - sparse_categorical_accuracy: 0.8210 - val_loss: 0.7127 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 487/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 0.6836 - sparse_categorical_accuracy: 0.7514 - val_loss: 0.7127 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 488/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 0.6822 - sparse_categorical_accuracy: 0.7866 - val_loss: 0.7128 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 489/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 0.6829 - sparse_categorical_accuracy: 0.7690 - val_loss: 0.7128 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 490/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.6828 - sparse_categorical_accuracy: 0.7719 - val_loss: 0.7128 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 491/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 0.6816 - sparse_categorical_accuracy: 0.8020 - val_loss: 0.7129 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 492/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 0.6834 - sparse_categorical_accuracy: 0.7541 - val_loss: 0.7129 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 493/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 0.6818 - sparse_categorical_accuracy: 0.7942 - val_loss: 0.7129 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 494/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 0.6819 - sparse_categorical_accuracy: 0.7928 - val_loss: 0.7129 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 495/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 0.6817 - sparse_categorical_accuracy: 0.7973 - val_loss: 0.7130 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 496/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 0.6811 - sparse_categorical_accuracy: 0.8125 - val_loss: 0.7130 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 497/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 0.6818 - sparse_categorical_accuracy: 0.7945 - val_loss: 0.7130 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 498/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 0.6859 - sparse_categorical_accuracy: 0.6899 - val_loss: 0.7130 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 499/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6802 - sparse_categorical_accuracy: 0.8341 - val_loss: 0.7131 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 500/500\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - loss: 0.6820 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.7131 - val_sparse_categorical_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = kdm_model.fit(\n",
    "    np.array(X_train),  # Your training data\n",
    "    np.array(y_out),  # Your training labels\n",
    "    batch_size=2,\n",
    "    epochs=500, \n",
    "    verbose=1,  # Detailed logging\n",
    "    validation_split=0.1,  # Explicit validation data\n",
    "    shuffle=True  # Shuffle the data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6905 - sparse_categorical_accuracy: 0.7388\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6917 - sparse_categorical_accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "\n",
    "check_full = kdm_model.evaluate(np.array(input), np.array(y_out))\n",
    "check_test = kdm_model.evaluate(np.array(X_test), np.array([y[0] for y in y_test]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Dataset loss: 0.6919097900390625\n",
      "Full Dataset accuracy: 0.6103895902633667\n",
      "Test loss: 0.6917439699172974\n",
      "Test accuracy: 0.625\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Full Dataset loss:', check_full[0])\n",
    "print('Full Dataset accuracy:', check_full[1])\n",
    "\n",
    "\n",
    "print('Test loss:', check_test[0])\n",
    "print('Test accuracy:', check_test[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
